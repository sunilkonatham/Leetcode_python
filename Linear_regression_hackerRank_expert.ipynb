{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e36eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "2 7\n",
    "0.18 0.89 109.85\n",
    "1.0 0.26 155.72\n",
    "0.92 0.11 137.66\n",
    "0.07 0.37 76.17\n",
    "0.85 0.16 139.75\n",
    "0.99 0.41 162.6\n",
    "0.87 0.47 151.77\n",
    "4\n",
    "0.49 0.18\n",
    "0.57 0.8\n",
    "0.56 0.64\n",
    "0.76 0.18\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f9c20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "6 15\n",
    "0.87 0.69 0.37 0.22 0.16 0.99 72.38\n",
    "0.24 0.42 0.23 0.75 0.3 0.56 107.39\n",
    "0.55 0.54 0.25 0.44 0.02 0.63 74.76\n",
    "0.39 0.36 0.82 0.99 0.49 0.6 152.03\n",
    "0.4 0.76 0.52 0.76 0.58 0.03 140.92\n",
    "0.2 0.43 0.5 0.04 0.12 0.86 68.63\n",
    "0.74 0.59 0.12 0.65 0.92 0.54 146.89\n",
    "0.36 0.19 0.01 0.03 0.34 0.79 78.62\n",
    "0.38 0.49 0.32 0.34 0.31 0.67 96.13\n",
    "0.07 0.65 0.97 0.03 0.92 0.94 151.32\n",
    "0.68 0.65 0.52 0.03 0.4 0.45 87.63\n",
    "0.26 0.82 0.58 0.07 0.99 0.73 146.44\n",
    "0.29 0.48 0.36 0.29 0.71 0.32 125.81\n",
    "0.46 0.67 0.7 0.79 0.98 0.88 179.37\n",
    "0.61 0.2 0.68 0.51 0.31 0.05 108.08\n",
    "76\n",
    "0.15 0.39 0.06 0.61 0.33 0.09\n",
    "0.54 0.14 0.53 0.01 0.93 0.78\n",
    "0.69 0.74 0.07 0.84 0.13 0.64\n",
    "0.92 0.04 0.24 0.5 0.19 0.34\n",
    "0.82 0.03 0.9 0.87 0.4 0.22\n",
    "0.31 0.21 0.56 0.27 0.83 0.84\n",
    "0.79 0.83 0.64 0.82 0.39 0.46\n",
    "0.58 0.37 0.81 0.34 0.77 0.98\n",
    "0.01 0.9 0.15 0.43 0.9 0.77\n",
    "0.76 0.76 0.49 0.01 0.95 0.14\n",
    "0.69 0.31 0.8 0.08 0.36 0.35\n",
    "0.62 0.63 0.46 0.26 0.01 0.51\n",
    "0.7 0.91 0.95 0.35 0.47 0.59\n",
    "0.16 0.16 0.81 0.02 0.04 0.77\n",
    "0.98 0.85 0.34 0.68 0.74 0.25\n",
    "0.98 0.86 0.08 0.62 0.25 0.42\n",
    "0.76 0.78 0.61 0.03 0.02 0.65\n",
    "0.5 0.07 0.08 0.8 0.23 0.28\n",
    "0.13 0.42 0.19 0.52 0.94 0.44\n",
    "0.03 0.89 0.03 0.52 0.37 0.21\n",
    "0.68 0.5 0.92 0.9 0.66 0.79\n",
    "0.74 0.7 0.21 0.88 0.4 0.07\n",
    "0.37 0.8 0.6 0.65 0.86 0.95\n",
    "0.2 0.32 0.61 0.55 0.52 0.61\n",
    "0.61 0.93 0.49 0.37 0.59 0.63\n",
    "0.3 0.07 0.55 0.2 0.72 0.46\n",
    "0.52 0.74 0.39 0.12 0.16 0.7\n",
    "0.46 0.82 0.21 0.27 0.2 0.36\n",
    "0.14 0.48 0.61 0.19 0.81 0.99\n",
    "0.75 0.93 0.04 0.32 0.65 0.09\n",
    "0.72 0.75 0.82 0.41 0.17 0.61\n",
    "0.4 0.92 0.91 0.57 0.47 0.13\n",
    "0.3 0.9 0.8 0.83 0.25 0.51\n",
    "0.25 0.61 0.49 0.51 0.18 0.75\n",
    "0.72 0.82 0.94 0.3 0.91 0.21\n",
    "0.41 0.49 0.59 0.99 0.58 0.8\n",
    "0.32 0.25 0.48 0.32 0.38 0.97\n",
    "0.7 0.61 0.65 0.21 0.31 0.69\n",
    "0.8 0.48 0.11 0.57 0.26 0.95\n",
    "0.84 0.22 0.27 0.74 0.26 0.74\n",
    "0.81 0.61 0.35 0.35 0.43 0.15\n",
    "0.57 0.36 0.28 0.65 0.97 0.66\n",
    "0.45 0.43 0.7 0.72 0.03 0.19\n",
    "0.59 0.09 0.9 0.61 0.89 0.38\n",
    "0.9 0.66 0.5 0.37 0.27 0.12\n",
    "0.4 0.28 0.76 0.67 0.89 0.51\n",
    "0.5 0.91 0.12 0.32 0.16 0.79\n",
    "0.64 0.96 0.27 0.18 0.11 0.55\n",
    "0.32 0.79 0.7 0.03 0.87 0.42\n",
    "0.82 0.2 0.48 0.07 0.11 0.52\n",
    "0.38 0.77 0.88 0.68 0.41 0.64\n",
    "0.69 0.03 0.2 0.91 0.85 0.26\n",
    "0.34 0.15 0.73 0.64 0.39 0.52\n",
    "0.97 0.25 0.12 0.1 0.08 0.65\n",
    "0.1 0.96 0.71 0.0 0.37 0.19\n",
    "0.42 0.89 0.31 0.34 0.35 0.01\n",
    "0.88 0.78 0.92 0.6 0.3 0.45\n",
    "0.8 0.02 0.32 0.18 0.05 0.1\n",
    "0.53 1.0 0.28 0.8 0.04 0.19\n",
    "0.59 0.02 0.1 0.04 0.56 0.12\n",
    "0.95 0.27 0.86 0.1 0.67 0.14\n",
    "0.76 0.43 0.74 0.17 0.89 0.31\n",
    "0.81 0.33 0.85 0.17 0.21 0.56\n",
    "0.72 1.0 0.7 0.46 0.79 0.2\n",
    "1.0 0.67 0.05 0.63 0.68 0.26\n",
    "0.05 0.83 0.75 0.53 0.5 0.11\n",
    "0.4 0.56 0.49 0.99 0.02 0.88\n",
    "0.04 0.23 0.15 0.47 0.73 0.7\n",
    "0.7 0.25 0.77 0.99 0.65 0.09\n",
    "0.23 0.22 0.56 0.18 0.43 0.6\n",
    "0.86 0.05 0.61 0.03 0.75 0.04\n",
    "0.27 0.58 0.83 0.56 0.43 0.86\n",
    "0.94 0.17 0.66 0.85 0.06 0.62\n",
    "0.56 0.03 0.32 0.99 0.79 0.69\n",
    "0.86 0.03 0.29 0.17 0.57 0.44\n",
    "0.43 0.16 0.93 0.82 0.25 0.59\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa14fdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 74.25905049 151.36716515  62.05372687  87.29673705 152.12386879\n",
      " 151.28642899 115.10456798 164.99979476 107.50170231 123.32617285\n",
      " 133.83856478  85.46301895 142.0112353  132.26084934 102.46689156\n",
      "  59.24307093  94.11923103  79.72835363 118.9019899   64.07021882\n",
      " 164.95528891  79.12435669 145.23649248 136.44138605 111.84292148\n",
      " 142.50689892  87.36960774  69.30015622 150.92726048  69.35493824\n",
      " 121.02106072 135.37755399 123.93042984 104.51375425 159.1007684\n",
      " 137.41545795 123.76948946 117.78368123  80.0455183   96.7028148\n",
      "  91.63732376 129.64039178 109.76238418 177.52853056  93.59423338\n",
      " 165.43363087  64.2014832   67.23254748 143.12829247  99.79431542\n",
      " 141.80561772 119.84900518 141.84668227  69.07975773 113.32849557\n",
      "  78.67743072 132.29085871  82.88481309  62.72721092  91.4898029\n",
      " 149.99012254 151.73111416 132.63501146 130.3365859   80.16852585\n",
      " 128.29163187 101.27763963 114.03968116 148.4762619  127.87670515\n",
      " 137.90123949 146.67428164 117.49383191 134.27347311 110.38054649\n",
      " 152.13806418]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sys.stdin = StringIO(text1)\n",
    "n = sys.stdin.readline().split()\n",
    "if not n:\n",
    "    n = sys.stdin.readline().split()\n",
    "\n",
    "for i in range(len(n)):\n",
    "    n[i] = int(n[i])\n",
    "\n",
    "data_dict = {}\n",
    "for i in range(n[0]+1):\n",
    "    data_dict['x'+str(i)] = []\n",
    "    \n",
    "for j in range(n[1]):\n",
    "    lines = sys.stdin.readline().split()\n",
    "    for i in range(n[0]+1):\n",
    "        data_dict['x'+str(i)].append(float(lines[i]))\n",
    "\n",
    "df = pd.DataFrame(data_dict)        \n",
    "x = df.drop(df.columns[-1], axis=1) #X_train\n",
    "y = df[df.columns[-1]]              #Y_train\n",
    "\n",
    "n_test = int(sys.stdin.readline().split()[0])\n",
    "\n",
    "data_dict_test = {}\n",
    "for i in range(n[0]):\n",
    "    data_dict_test['x'+str(i)] = []\n",
    "    \n",
    "for j in range(n_test):\n",
    "    lines = sys.stdin.readline().split()\n",
    "    for i in range(n[0]):\n",
    "        data_dict_test['x'+str(i)].append(float(lines[i]))\n",
    "        \n",
    "x_test = pd.DataFrame(data_dict_test)    #X_test\n",
    "\n",
    "# As the above variables has have multicolinearity, we will apply PCA\n",
    "def apply_pca(x):\n",
    "    col = []\n",
    "    n_comp = len(x.columns)\n",
    "    \n",
    "    #applying standard scalar before PCA\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    \n",
    "    #Applying PCA in for floop\n",
    "    for i in range(1,n_comp):\n",
    "        n_components=i\n",
    "        pca = PCA(n_components=i)\n",
    "        p_comp = pca.fit_transform(x)\n",
    "        evr = np.cumsum(pca.explained_variance_ratio_)\n",
    "        if evr[i-1]>0.9:\n",
    "            n_components = i\n",
    "            break\n",
    "    \n",
    "    \n",
    "    #creating data frame\n",
    "    for j in range(1,n_components+1):\n",
    "        col.append('pc'+str(j))\n",
    "        \n",
    "    result = pd.DataFrame(data = p_comp, columns=col)\n",
    "    return result\n",
    "\n",
    "x = apply_pca(df.drop(df.columns[-1], axis=1))\n",
    "y = df[df.columns[-1]]\n",
    "pca_df_test = apply_pca(x_test)\n",
    "\n",
    "#x = pca_df.drop(pca_df.columns[-1], axis=1)\n",
    "#y = pca_df[pca_df.columns[-1]]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "print(lr.predict(pca_df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0512f8",
   "metadata": {},
   "source": [
    "# Submitted in Hacker rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n = sys.stdin.readline().split()\n",
    "if not n:\n",
    "    n = sys.stdin.readline().split()\n",
    "\n",
    "for i in range(len(n)):\n",
    "    n[i] = int(n[i])\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "for i in range(n[0]+1):\n",
    "    data_dict['x'+str(i)] = []\n",
    "    \n",
    "for j in range(n[1]):\n",
    "    lines = sys.stdin.readline().split()\n",
    "    for i in range(n[0]+1):\n",
    "        data_dict['x'+str(i)].append(float(lines[i]))\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "x = df.drop([df.columns[-1]], axis=1)\n",
    "y = df[[df.columns[-1]]]\n",
    "\n",
    "n_test = int(sys.stdin.readline().split()[0])\n",
    "\n",
    "data_dict_test = {}\n",
    "for i in range(n[0]):\n",
    "    data_dict_test['x'+str(i)] = []\n",
    "    \n",
    "for j in range(n_test):\n",
    "    lines = sys.stdin.readline().split()\n",
    "    for i in range(n[0]):\n",
    "        data_dict_test['x'+str(i)].append(float(lines[i]))\n",
    "        \n",
    "x_test = pd.DataFrame(data_dict_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "lr_pred = lr.predict(x_test)\n",
    "\n",
    "for i in lr_pred:\n",
    "    print(f\"{i[0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
